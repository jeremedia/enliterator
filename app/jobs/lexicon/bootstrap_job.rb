# frozen_string_literal: true

module Lexicon
  # Job to bootstrap the lexicon from triaged data items
  # This is Stage 3 of the Zero-touch Pipeline
  # - Extracts canonical terms from content
  # - Generates surface forms and negative surface forms
  # - Creates canonical descriptions
  # - Normalizes names and casing
  class BootstrapJob < ApplicationJob
    queue_as :pipeline

    def perform(ingest_batch_id)
      @batch = IngestBatch.find(ingest_batch_id)
      @extracted_terms = []

      Rails.logger.info "Starting lexicon bootstrap for batch #{@batch.id}"

      # Update batch status
      @batch.update!(status: 'lexicon_in_progress')

      # Process items that have completed rights triage
      @batch.ingest_items.where(triage_status: 'completed').find_each do |item|
        extract_terms_from_item(item)
      end

      # Deduplicate and normalize extracted terms
      normalized_terms = normalize_and_deduplicate_terms
      
      # Create or update lexicon entries
      create_lexicon_entries(normalized_terms)

      finalize_batch_lexicon
    rescue StandardError => e
      Rails.logger.error "Failed to bootstrap lexicon for batch #{@batch.id}: #{e.message}"
      @batch.update!(status: 'failed', metadata: @batch.metadata.merge(
        lexicon_error: { message: e.message, backtrace: e.backtrace.first(5) }
      ))
      raise
    end

    private

    def extract_terms_from_item(item)
      return if item.content.blank?

      # Use the term extraction service with OpenAI Structured Outputs
      extraction_result = Lexicon::TermExtractionService.new(
        content: item.content,
        source_type: item.source_type,
        metadata: item.metadata
      ).extract

      if extraction_result[:success]
        @extracted_terms.concat(extraction_result[:terms])
        
        # Update item with extraction metadata
        item.update!(
          lexicon_status: 'extracted',
          lexicon_metadata: {
            terms_count: extraction_result[:terms].size,
            extraction_confidence: extraction_result[:confidence],
            extracted_at: Time.current
          }
        )
      else
        Rails.logger.warn "Failed to extract terms from item #{item.id}: #{extraction_result[:error]}"
        item.update!(
          lexicon_status: 'failed',
          lexicon_metadata: { error: extraction_result[:error] }
        )
      end
    rescue StandardError => e
      Rails.logger.error "Error processing item #{item.id}: #{e.message}"
      item.update!(
        lexicon_status: 'failed',
        lexicon_metadata: { error: e.message }
      )
    end

    def normalize_and_deduplicate_terms
      service = Lexicon::NormalizationService.new(@extracted_terms)
      service.normalize_and_deduplicate
    end

    def create_lexicon_entries(normalized_terms)
      normalized_terms.each do |term_data|
        # Find or create the lexicon entry
        lexicon_entry = LexiconAndOntology.find_or_initialize_by(
          term: term_data[:canonical_term]
        )

        # Merge surface forms
        existing_surface_forms = lexicon_entry.surface_forms || []
        new_surface_forms = (existing_surface_forms + term_data[:surface_forms]).uniq

        # Merge negative surface forms
        existing_negative_forms = lexicon_entry.negative_surface_forms || []
        new_negative_forms = (existing_negative_forms + term_data[:negative_surface_forms]).uniq

        # Ensure ProvenanceAndRights is attached for new records
        if lexicon_entry.new_record? || lexicon_entry.provenance_and_rights.nil?
          lexicon_entry.provenance_and_rights = create_lexicon_provenance
        end

        # Update the entry
        lexicon_entry.update!(
          definition: term_data[:canonical_description] || lexicon_entry.definition || 'Term extracted from content',
          canonical_description: term_data[:canonical_description] || lexicon_entry.canonical_description,
          surface_forms: new_surface_forms,
          negative_surface_forms: new_negative_forms,
          pool_association: term_data[:term_type] || lexicon_entry.pool_association || 'general',
          type_mapping: merge_type_mapping(lexicon_entry.type_mapping, term_data[:metadata]),
          is_canonical: true,
          # repr_text will be auto-generated by the model's callback
          valid_time_start: Time.current
        )
      end
    end

    def merge_type_mapping(existing, new_metadata)
      existing ||= {}
      new_metadata ||= {}
      
      {
        sources: ((existing['sources'] || []) + (new_metadata['sources'] || [])).uniq,
        confidence_scores: ((existing['confidence_scores'] || []) + [new_metadata['confidence']]).compact,
        extraction_count: (existing['extraction_count'] || 0) + 1,
        last_extracted_at: Time.current.iso8601
      }
    end

    def create_lexicon_provenance
      ProvenanceAndRights.create!(
        source_ids: ["lexicon_bootstrap_#{@batch.id}"],
        collectors: ['Enliterator Lexicon Bootstrap'],
        collection_method: 'automated_extraction',
        consent_status: 'implicit_consent',
        license_type: 'cc0',
        source_owner: 'Enliterator System',
        custom_terms: {
          system_generated: true,
          batch_id: @batch.id,
          generated_at: Time.current
        },
        valid_time_start: Time.current
      )
    end

    def finalize_batch_lexicon
      # Count results
      successful_items = @batch.ingest_items.where(lexicon_status: 'extracted').count
      failed_items = @batch.ingest_items.where(lexicon_status: 'failed').count
      total_terms = LexiconAndOntology.count

      # Update batch metadata
      @batch.update!(
        status: 'lexicon_completed',
        metadata: @batch.metadata.merge(
          lexicon_results: {
            successful_items: successful_items,
            failed_items: failed_items,
            total_terms_extracted: @extracted_terms.size,
            unique_canonical_terms: total_terms,
            completed_at: Time.current
          }
        )
      )

      Rails.logger.info "Lexicon bootstrap completed for batch #{@batch.id}: #{successful_items} items processed, #{total_terms} terms in lexicon"

      # Trigger next stage if successful
      if failed_items == 0 || failed_items < successful_items * 0.1 # Less than 10% failed
        # TODO: Trigger Stage 4 - Pool Filling
        # Pools::ExtractionJob.perform_later(@batch.id)
        Rails.logger.info "Batch #{@batch.id} ready for pool filling stage"
      end
    end
  end
end