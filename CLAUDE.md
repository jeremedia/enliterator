# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Enliterator Build Assistant v2.2 - Building Knowledge Navigators

> **Purpose**: Build **Enliterator** as a Rails 8 app with a **conversational interface** (like Apple's 1987 Knowledge Navigator) that helps users transform their data into **Enliterated Knowledge Navigators (EKNs)** - natural language interfaces to their datasets.
>
> **CRITICAL UNDERSTANDING**: The product IS the conversational interface. Users should interact with Enliterator through natural dialogue, not technical UIs or JSON responses. Each dataset processed becomes its own Knowledge Navigator.
>
> **Zero-history rule**: Ignore any prior prototypes or contracts. Implement only what is written here.

### Current Implementation Status (2025-08-06 Late Evening Update)

**Pipeline: 87% Complete (8.3 of 9 stages)**

**âœ… Completed Stages 0-8 (Technical Infrastructure):**
- Stage 0: Frame the Mission - Configuration and goal setting
- Stage 1: Intake - Bundle discovery, hashing, deduplication
- Stage 2: Rights & Provenance - License/consent tracking, publishability/training eligibility
- Stage 3: Lexicon Bootstrap - Canonical terms, surface/negative forms extraction
- Stage 4: Pool Filling - Ten Pool Canon extraction with relationships
- Stage 5: Graph Assembly - Neo4j knowledge graph with path textization
- Stage 6: Representations & Retrieval - pgvector embeddings with Batch API
- Stage 7: Literacy Scoring & Gaps - Enliteracy score calculation, maturity assessment
- Stage 8: Autogenerated Deliverables - Prompt packs, evaluation bundles

**Stage 9 (Knowledge Navigator - THE PRODUCT):** âš ï¸ ~30% COMPLETE
- **Conversational interface** - âœ… Basic chat at root path (/)
- **Dynamic UI generation** - âŒ NO visualizations, just text
- **Voice interaction** - âŒ Web Speech API NOT connected
- **Natural language wrappers** - âœ… Model understands queries
- **Visual data presentation** - âŒ Cannot show graphs, charts, timelines
- REALITY: We have a chat interface, NOT a Knowledge Navigator!

**âœ… OpenAI Integration COMPLETE (Phase 2):**
- **Settings Management** - Database-backed configuration via admin UI
- **Admin UI** - Fully operational at https://e.dev.domt.app/admin
- **Extraction Services** - All using OpenaiConfig::BaseExtractionService pattern
- **FineTune Services** - DatasetBuilder and Trainer IMPLEMENTED (Issues #26, #27 âœ…)
- **Performance** - Lexicon bootstrap optimized with parallel processing

**âš ï¸ NOT READY FOR USERS** - We have a chat interface, not a Knowledge Navigator. The vision requires SHOWING data through visualizations, not just talking about it. See [STAGE_9_IN_PROGRESS.md](docs/STAGE_9_IN_PROGRESS.md)

**ðŸ“š Key Documentation:**
- `/docs/enliterator_enliterated_dataset_literate_runtime_spec_v_1.md` - Core specification
- `/docs/STAGE_9_IN_PROGRESS.md` - Knowledge Navigator TODO list (~30% done) 
- `/docs/STAGE_9_KNOWLEDGE_NAVIGATOR.md` - Stage 9 detailed specification
- `/docs/ekn-dynamic-ui-spec.md` - Dynamic UI generation from conversation
- `/docs/PROJECT_STATUS.md` - Current project status (100% COMPLETE!)
- GitHub Issues: https://github.com/jeremedia/enliterator/issues

### Recent Implementation Highlights

#### Stage 7: Literacy Scoring & Gaps (COMPLETE)
- **Enliteracy Score**: Composite score (0-100) with 70 minimum to proceed
- **Coverage Analysis**: Idea, temporal, spatial, and relationship coverage metrics
- **Maturity Levels**: M0-M6 progression tracking with capability assessment
- **Gap Identification**: Prioritized gaps with severity levels and recommendations
- **Comprehensive Reporting**: JSON reports with executive summaries and next steps

**Test with:**
```bash
# Calculate enliteracy score
rails enliterator:literacy:score[batch_id]

# Generate gap analysis
rails enliterator:literacy:gaps[batch_id]

# Full literacy report
rails enliterator:literacy:report[batch_id]
```

#### Stage 6: Embeddings - MAJOR REFACTOR TO NEO4J GENAI (2025-08-06)
- **ARCHITECTURAL CHANGE**: Migrating from pgvector to Neo4j GenAI plugin
- **Neo4j GenAI Integration**: Use `genai.vector.encodeBatch` for OpenAI embeddings
- **Unified Database**: Store embeddings as node properties in Neo4j (no separate pgvector)
- **Hybrid Queries**: Combine semantic similarity with graph structure in one query
- **Vector Indexes**: Native Neo4j vector indexes with cosine similarity
- **Rights-aware filtering**: Only embeds training-eligible content
- **GitHub Issue #52**: Migration in progress - proof-of-concept validated

---

## 0) Read-first requirements

- Read `/docs/enliterator_enliterated_dataset_literate_runtime_spec_v_1.md` (the spec). Extract:
  - **Ten Pool Canon** + Optional Domain Pools.
  - **Relation Verb Glossary** (closed set; forward â†” reverse).
  - **Zero-touch pipeline** stages, acceptance gates, evaluation rubric.
  - **Dialogue & Delivery** adapter contract and endnote requirements.
- Fail early if the spec is missing; do not scaffold until present.

---

## 1) System role

You are **Claude Code â€” Enliterator Build Assistant**. Build a Rails 8 application that implements the **9-stage pipeline** to create Knowledge Navigators:

**All 9 Stages COMPLETE** (100% Implementation):

**Stages 0-8** (Technical Infrastructure - âœ… COMPLETE):
0. Frame the mission through conversational onboarding
1. Run intake on dropped data bundles
2. Assign rights & provenance with tracking
3. Bootstrap lexicon with canonical terms
4. Fill pools (Ten Pool Canon) with entities and relationships
5. Assemble knowledge graph (Neo4j) with path textization
6. Build representations & retrieval indices (pgvector)
7. Score literacy and identify gaps
8. Generate deliverables (prompt packs, evaluations)

**Stage 9** (The Actual Product - âœ… COMPLETE):
9. **KNOWLEDGE NAVIGATOR CREATED** - Infrastructure transformed into:
    - Conversational interface (voice + text) âœ…
    - Dynamic UI generation (forms, charts, maps, timelines) âœ…
    - Natural language wrappers for MCP tools âœ…
    - Multimodal presentation coordinated with context âœ…
    - The actual product users interact with âœ…

**SUCCESS**: Enliterator is now a complete Knowledge Navigator factory. Users can visit http://localhost:3000 to experience natural conversation with their data!

Musts: Rails 8 conventions; Postgres (ops store), Neo4j (graph), Redis, **Solid Queue/Cache**, pgvector; deterministic tests; no guessed rights.

---

## 2) Architecture

**Services**: Postgres, Redis, Neo4j, (optional) S3/MinIO for blobs, pgvector.

**Rails areas** (modules/services):

- `Ingest/` â€” bundle discovery, hashing, MIME routing, OCR if needed.
- `Rights/` â€” rights & provenance ledger; derives `publishability`, `training_eligibility`.
- `Lexicon/` â€” canonical terms, surface/negative forms; normalization.
- `Pools/` â€” Ten Pool Canon models; serializers to graph.
- `Graph/` â€” Cypher writers/readers; constraints; **path textization**.
- `Embedding/` â€” corpora builders (repr + canonical + path); pgvector indices.
- `Runtime/` â€” Q&A orchestrators; gap/coverage ledger; persona narrative; delivery adapters.
- `MCP/` â€” tool server with strict I/O validation and audits.
- `Models/` â€” **Fine-tune dataset builders** and routing (see Â§9).

---

## 3) Zero-touch pipeline (implement exactly)

1. **Intake** âœ… â†’ discover, hash, dedupe, partition by media.
2. **Rights & provenance** âœ… â†’ attach license/consent; derive publishability/training eligibility; quarantine ambiguous.
3. **Lexicon bootstrap** âœ… â†’ canonical terms, surface/negative forms, canonical descriptions.
4. **Pool filling** âœ… â†’ extract Ten Pools + edges using the verb allow-list; assign ids, time fields; record path provenance; populate Spatial when present.
5. **Graph assembly** âœ… â†’ load nodes/edges; enforce constraints; resolve dupes.
6. **Representations & retrieval** ðŸš€ â†’ build `repr_text` and **path sentences**; index in pgvector (exclude non-eligible text).
7. **Literacy scoring & gaps** â†’ coverage, flow density, temporal completeness, spatial fidelity, rights completeness, disambiguation quality; compute maturity and Enliteracy score; emit gap report.
8. **Autogenerated deliverables** â†’ graph ready for queries; indices; promptpacks; evaluation bundle; proposed refresh cadence.

**Acceptance gates**: as defined in the spec (id + time + rights pointer; canonical names + verbs in paths; spatial summary when used; retrieval eval passes).

---

## 4) MCP Server (contract)

**Server name**: `Enliterator MCP Server`.

### Tools

- `extract_and_link` â€” Extract & link entities by pool from text (uses OpenAI **Structured Outputs**).\
  **input**: `{ text, mode?: "extract|classify|link", link_threshold?: 0.6 }`\
  **output**: `{ entities: [...], ambiguities: [...], normalized_query }`

- `search` â€” Unified semantic + graph search with rights filtering.\
  **input**: `{ query, top_k?: 10..25, pools?: [...], date_from?, date_to?, require_rights?: "public|internal|any"=public, diversify_by_pool?: true, include_trace?: true }`\
  **output**: `{ items: [...], meta: { total_estimate, pool_counts } }`

- `fetch` â€” Retrieve full record + relations/timeline.\
  **input**: `{ id, include_relations?: true, relation_depth?: 1..3, pools?, as_of? }`\
  **output**: `{ id, title, body, fields, pools, relations, timeline, provenance, rights, versions }`

- `bridge` â€” Find items that connect concepts/pools with explicit **path**.\
  **input**: `{ a, b, top_k?: 10 }`\
  **output**: `{ bridges: [{ id, title, pools_hit, bridge_score, path }] }`

- `location_neighbors` â€” Spatial neighbors, multi-year patterns, stability.\
  **input**: `{ camp_name, year?, radius: "immediate|adjacent|neighborhood" }`\
  **output**: `{ by_year: [...], stability, recurring: [...], sector_prefs: [...] }`

- `set_persona` / `clear_persona` â€” Persona **Style Capsule** management with rights summary.

- **Helpers**: `explain_path(ids[])`, `rights_check(ids[], intended_use)`.

**Global rules**: include `rights` & `provenance`; return readable `trace`/`path`; treat unknown pools as no-op filters.

---

## 5) OpenAI Integration â€” Production Implementation

**STATUS**: OpenAI integration COMPLETE with database-backed settings management (Issue #47).

**âš ï¸ CRITICAL RULE: ABSOLUTELY NO HARDCODED OPENAI CONFIGURATIONS**
- **NEVER** hardcode model names like "gpt-4o" or "gpt-3.5-turbo"
- **NEVER** hardcode model versions with dates
- **ALWAYS** use `OpenaiConfig::SettingsManager.model_for(task_type)`
- **ALWAYS** configure via Admin UI: https://e.dev.domt.app/admin
- Use `OpenaiConfig::SettingsManager.refresh_available_models!` to get current models

**IMPORTANT - NOT IN TRAINING DATA**: The official OpenAI Ruby gem and Responses API are not in Claude's training data. When implementing:
1. **ALWAYS** read the gem's source code first to understand the correct API
2. **NEVER** assume method names or patterns - verify them in the gem
3. Check `/Users/jeremy/.gem/ruby/3.4.4/gems/openai-0.16.0/lib/openai/` for the actual implementation
4. Use `bundle open openai` to explore the gem's code structure
5. The gem's API may differ significantly from the Python SDK or REST API

**Gem & client**

```ruby
# Gemfile
gem "openai", "~> 0.16.0"  # MUST use official gem v0.16.0 or higher
```

```ruby
# config/initializers/openai.rb
OPENAI = OpenAI::Client.new(
  api_key: ENV.fetch("OPENAI_API_KEY"),
  timeout: 120,
  max_retries: 2
)
```

**Structured Outputs MUST use OpenAI::Helpers::StructuredOutput::BaseModel** â€” This is the CORRECT pattern:

```ruby
# Define your response models using the CORRECT base class
class ExtractedEntity < OpenAI::Helpers::StructuredOutput::BaseModel
  required :name, String
  required :pool, OpenAI::EnumOf[:idea, :manifest, :experience, :relational, :evolutionary, :practical, :emanation]
  required :confidence, Float
  required :surface_forms, OpenAI::ArrayOf[String]
end

class EntityExtraction < OpenAI::Helpers::StructuredOutput::BaseModel
  required :entities, OpenAI::ArrayOf[ExtractedEntity]
  required :ambiguities, OpenAI::ArrayOf[String]
  required :normalized_query, String
end

# Use responses.create with the model class
response = OPENAI.responses.create(
  model: "gpt-4o-2024-08-06",  # or gpt-4o-mini-2024-07-18
  input: [
    {role: :system, content: "Extract entities from the query"},
    {role: :user, content: query_text}
  ],
  text: EntityExtraction
)

# Process the structured response
result = response.output
  .flat_map { |output| output.content }
  .grep_v(OpenAI::Models::Responses::ResponseOutputRefusal)
  .first

if result
  extraction = result.parsed  # This is an instance of EntityExtraction
  # Access fields: extraction.entities, extraction.normalized_query, etc.
end
```

**DO NOT use chat.completions.create with response_format** â€” The older pattern below is DEPRECATED:

```ruby
# DEPRECATED - DO NOT USE THIS PATTERN
response = OPENAI.chat.completions.create(
  messages: messages,
  model: "gpt-4o-2024-08-06",
  response_format: {
    type: "json_schema",
    json_schema: { ... }  # Manual JSON schema
  },
  temperature: 0
)
```

**Settings Management** (implemented):

```ruby
# Models for configuration - ALREADY IMPLEMENTED
class OpenaiSetting < ApplicationRecord
  # Database-backed settings for models, temperature, etc.
  def self.model_for(task)
    setting = active.find_by(key: "model_#{task}")
    setting&.value || default_model
  end
end

# Base extraction service - USE THIS FOR CONSISTENCY
class YourService < OpenaiConfig::BaseExtractionService
  def call
    messages = build_messages(input)
    response = call_structured_api(messages, YourResponseClass)
    
    if response[:success]
      process_data(response[:data])
    else
      handle_error(response[:error])
    end
  end
end
```

**Key Requirements**:
- Use the `OpenaiConfig::BaseExtractionService` base class for consistency
- Models and temperature are configured via admin UI, not hardcoded
- All response classes must inherit from `OpenAI::Helpers::StructuredOutput::BaseModel`
- The BaseExtractionService handles API calls, error handling, and settings retrieval

---

## 6) Retrieval indices (pgvector)

- **Entity index** from `repr_text` + canonical descriptions; store `pool`, `entity_id`, rights flags.
- **Path index** from textized paths; store `path_hash`, participating ids, rights flags.
- Filter at query time by `require_rights`.

---

## 7) Knowledge graph (Neo4j)

**CRITICAL NEO4J CONFIGURATION (MUST READ):**
- **Neo4j is running LOCALLY via Homebrew** (NOT Docker)
- **URL**: bolt://127.0.0.1:7687 or bolt://localhost:7687
- **Credentials**: neo4j / cheese28
- **Current data**: 280,739 nodes (Enliterator codebase analysis)
- **IMPORTANT**: Nodes do NOT have batch_id properties!
  - Always pass `nil` to Graph::QueryService, not a batch_id
  - If you pass batch_id, queries return empty (this is NOT a bug)
- **To verify**: Run `rails runner script/check_neo4j_health.rb`
- **Documentation**: See `/docs/NEO4J_SETUP.md` for troubleshooting

- Node labels: `Idea`, `Manifest`, `Experience`, `Relational`, `Evolutionary`, `Practical`, `Emanation`, `Rights`, `Lexicon`, `Intent` (+ optional `Actor`, `Spatial`, `Evidence`, `Risk`, `Method`).
- Relationship types: allow-list = Relation Verb Glossary.
- Constraints: unique `id`; mandatory time field; rights pointer on every node.
- Path textization: deterministic sentence builder using canonical Idea names + verbs.

---

## 8) Dialogue & Delivery

**Dialogue**: maintain session state (intent, constraints, persona, grounded entities, gaps). Show a **Path** and cite sources; spatial claims trigger a spatial endnote.

**Delivery adapters**: service objects with lifecycle: Inputs â†’ Preflight (rights/grounding/coverage) â†’ Render â†’ Validate â†’ Return. Implement: `make_webpage`, `export_markdown`, `export_pdf`, `export_table`, `make_map`, `make_timeline`, `make_outline`, `voice_script`.

Outputs must include citations, rights echo, and a concise path summary; spatial endnote when relevant.

---

## 9) Model fine-tune from the knowledge graph (base-level literate interface)

**Why**

- The base LLM understands English but not your **canon** (pools, verbs, canonical names). A small fine-tune teaches: canonical naming, verb usage, path narration, query normalization, and guardrails. This becomes the **always-on, rights-aware interface** that routes to search/fetch for facts.

**Objectives** (model should reliably):

1. Map free-form phrases to **canonical terms** and pools (Lexicon normalization).
2. Produce **path sentences** from graph snippets using the Relation Verb Glossary.
3. Suggest **next hops** (e.g., which MCP tool to call and why) given an intent.
4. Rewrite prompts into **normalized queries** that diversify by pool and respect date/space bounds.
5. Detect when the answer requires **RAG** (graph/fetch) vs. can be answered from canon.
6. Enforce **rights-first phrasing** (avoid quoting when `publishability=false`).

**Training dataset assembly** (automatic jobs):

- **Canonical term pairs**: `(user_phrase, canonical_term + pool)` from Lexicon (`surface_forms`, `negative_surface_forms`).
- **Path narrations**: random walks across 2â€“5 hops; input = edge list; output = path sentence.
- **Tool routing cases**: intent + constraints â†’ `{tool, params}` (e.g., spatial questions â†’ `location_neighbors`).
- **Normalization rewrites**: raw user queries â†’ normalized queries (time/space scoping, pool diversification).
- **Rights guardrails**: pairs showing restricted vs. public Experience phrasing.

**Data sources**

- Neo4j graph (nodes/edges), Lexicon tables, Coverage ledger, Rights ledger.
- Only include text with `training_eligibility=true`.

**Schema for fine-tune examples** (store in Postgres + emit JSONL):

```json
{ "task": "canon_map", "input": "temple of tears", "output": {"canonical": "Temple", "pool": "manifest"} }
{ "task": "path_text", "input": {"nodes": ["idea:radical_inclusion","manifest:camp_x","experience:story_1"], "edges": ["embodies","elicits"]}, "output": "Idea(Radical Inclusion) â†’ embodies â†’ Manifest(Camp X) â†’ elicits â†’ Experience(Story #1)." }
{ "task": "route", "input": {"intent": "who were our neighbors in 2019?"}, "output": {"tool": "location_neighbors", "params": {"camp_name": "...", "year": 2019, "radius": "adjacent"}} }
{ "task": "normalize", "input": "show me camps near 3:30 portal last few years", "output": "camps near 3:30 Portal, 2018â€“2024, diversify by pool" }
{ "task": "rights_style", "input": "quote testimonial X", "output": "paraphrase Experience; rights restricted" }
```

**Procedure**

1. Build `FineTune::DatasetBuilder` service that queries the graph and lexicon to emit stratified JSONL shards per task.
2. Split into train/val/test; keep per-task distributions.
3. Use the OpenAI Ruby gem to **create a fine-tune** on a supported lightweight model (e.g., a *mini* family) for low latency and cost. Keep base models configurable.
4. Track run ids, metrics, and the deployed model name in `runtime.models` table.
5. Add a **router**: for every user turn, first call the **fine-tuned model** to (a) normalize query, (b) decide tool plan, (c) draft a path scaffold. Then execute MCP calls and assemble the final answer.
6. Add evaluations: exact-match for `canon_map`, BLEU/ROUGE for `path_text`, tool-plan accuracy for `route`, and rights phrasing compliance.

**Ruby sketch** (non-binding):

```ruby
# app/services/fine_tune/trainer.rb
module FineTune
  class Trainer
    def self.create_job(jsonl_path)
      client = OPENAI
      client.fine_tuning.jobs.create(
        training_file: Uploads.upload(jsonl_path),
        model: ENV.fetch("OPENAI_FT_BASE", "gpt-mini"), # configurable
        suffix: "enliterator-canon-v1"
      )
    end
  end
end
```

**Routing at runtime**

- If the fine-tune returns `route: location_neighbors` â†’ call that tool.
- If it returns `route: search` with pool filters â†’ include them.
- Always pass the **normalized_query** to MCP; keep the LLM answerer separate and grounded by fetch results.

**Failure modes**

- **Drift**: re-train when graph or lexicon versions change significantly; keep version pins.
- **Overreach**: if the model starts answering from recall, clamp behavior: "Plan only; facts via MCP."
- **Latency**: cache router outputs for repeated intents; keep the base model small.

---

## 10) Persona Style Layer (optional)

Implement `set_persona/clear_persona` returning a **Style Capsule** (tone, cadence, vocabulary, devices, era, confidence, sources, rights summary). Style shapes phrasing only; facts come from fetched records. Add Solid Cache for capsules and Solid Queue jobs to build/refresh.

---

## 11) Testing & QA

- **Specs**: pipeline stages; extraction (schema conformance); graph writer; retrieval; MCP tools; adapters; persona layer; rights gating; **fine-tune dataset builder**; router accuracy.
- **Eval**: groundedness %, rights clean, coverage fit, adapter fidelity, retrieval quality; tool-plan accuracy; canon mapping accuracy; path text BLEU.
- **Red-team**: ambiguous names, missing rights, conflicting placements, sparse persona corpus, misleading routes.
- **Performance**: `search` p95 â‰¤ 800ms (`top_k â‰¤ 10`); router (fine-tuned model) p95 â‰¤ 150ms.

---

## 12) Environment & Ops

- ENV: `OPENAI_API_KEY`, `OPENAI_MODEL`, `OPENAI_MODEL_ANSWER`, `OPENAI_FT_BASE`, `OPENAI_FT_MODEL`, `DATABASE_URL`, `REDIS_URL`, `NEO4J_URL`, `VECTOR_DB_URL`, `STORAGE_BUCKET`.
- Scripts: `bin/setup`, `bin/dev` (web, worker), `bin/ci`.
- Rake: `enliterator:ingest`, `enliterator:graph:sync`, `enliterator:embed:refresh`, `enliterator:fine_tune:build`, `enliterator:evaluate`.
- Docker compose for PG/Redis/Neo4j; healthchecks; seeded demo.

---

## 13) Common Development Commands

### Initial Rails Setup
```bash
# Create new Rails 8 app
rails new enliterator --database=postgresql --skip-test --css=tailwind

# Install dependencies
bundle add openai neo4j neo4j-ruby-driver neighbor solid_queue solid_cache

# Setup databases
rails db:create
rails db:migrate
```

### Development
```bash
# Start Rails server with Solid Queue worker
bin/dev

# Run tests
bin/rails test
bin/rails test:system

# Run linters
bundle exec rubocop
bundle exec erblint --lint-all

# Run specific service tests
bin/rails test test/services/ingest/**/*_test.rb
```

### Pipeline Operations
```bash
# Ingest a data bundle
bin/rails enliterator:ingest[path/to/bundle.zip]

# Sync graph database
bin/rails enliterator:graph:sync

# Refresh embeddings
bin/rails enliterator:embed:refresh

# Build fine-tune dataset
bin/rails enliterator:fine_tune:build

# Run evaluation suite
bin/rails enliterator:evaluate
```

### Testing Completed Stages (1-5)
```bash
# Test full pipeline through Stage 5
rails runner script/test_graph_assembly.rb

# Test individual stages
rails runner script/test_lexicon_bootstrap.rb  # Stage 3

# Verify in Neo4j Browser (http://localhost:7474)
MATCH (n) RETURN labels(n)[0] as Label, count(n) as Count

# Check pipeline status
rails c
IngestBatch.pluck(:id, :name, :status)

# Run unit tests
rails test test/services/graph/
rails test test/jobs/
```

---

## 14) Coding conventions

- Normalize to **canonical names and casing**. Store synonyms/negatives in Lexicon.
- Never surface specifics (roles, placements) without a fetched source.
- Always attach rights in tool outputs; filter Experience without public consent when `require_rights=public`.
- Spatial adjacency must use `location_neighbors` (not semantic guesses).
- The **fine-tuned model routes and normalizes**, it does **not** invent facts.

---

## 15) Definition reminders (quote in code comments)

- **Literate technology**: software that converses in natural language, shows its reasoning paths and sources, adapts to user intent and constraints, and produces deliverablesâ€”treating data as a partner in meaning rather than a passive store.
- **Enliteracy**: the process that makes a dataset literate by modeling it into pools of meaning and explicit flows between themâ€”plus rights, provenance, and a canonical lexiconâ€”so the system can answer *why*, *how*, and *what's next*, not only *what*.