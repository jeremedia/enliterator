# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Enliterator Build Assistant v2.2 - Building Knowledge Navigators

> **Purpose**: Build **Enliterator** as a Rails 8 app with a **conversational interface** (like Apple's 1987 Knowledge Navigator) that helps users transform their data into **Enliterated Knowledge Navigators (EKNs)** - natural language interfaces to their datasets.
>
> **CRITICAL UNDERSTANDING**: The product IS the conversational interface. Users should interact with Enliterator through natural dialogue, not technical UIs or JSON responses. Each dataset processed becomes its own Knowledge Navigator.
>
> **Zero-history rule**: Ignore any prior prototypes or contracts. Implement only what is written here.

### Current Implementation Status (2025-08-08)

**Technical Pipeline: 92% Complete (8.3 of 9 stages)**
**Product Completion: ~60% (Infrastructure done, user experience incomplete)**

**‚úÖ Completed Stages 0-8 (Technical Infrastructure):**
- Stage 0: Frame the Mission - Configuration and goal setting
- Stage 1: Intake - Bundle discovery, hashing, deduplication
- Stage 2: Rights & Provenance - License/consent tracking, publishability/training eligibility
- Stage 3: Lexicon Bootstrap - Canonical terms, surface/negative forms extraction
- Stage 4: Pool Filling - Ten Pool Canon extraction with relationships
- Stage 5: Graph Assembly - Neo4j knowledge graph with path textization
- Stage 6: Representations & Retrieval - pgvector embeddings with Batch API
- Stage 7: Literacy Scoring & Gaps - Enliteracy score calculation, maturity assessment
- Stage 8: Autogenerated Deliverables - Prompt packs, evaluation bundles

**Stage 9 (Knowledge Navigator - THE PRODUCT):** ‚ö†Ô∏è ~30% COMPLETE
- **Conversational interface** - ‚úÖ Basic chat at root path (/)
- **Dynamic UI generation** - ‚ùå NO visualizations, just text
- **Voice interaction** - ‚ùå Web Speech API NOT connected
- **Natural language wrappers** - ‚úÖ Model understands queries
- **Visual data presentation** - ‚ùå Cannot show graphs, charts, timelines
- REALITY: We have a chat interface, NOT a Knowledge Navigator!

**‚úÖ OpenAI Integration COMPLETE (Phase 2):**
- **Settings Management** - Database-backed configuration via admin UI
- **Admin UI** - Fully operational at https://e.dev.domt.app/admin
- **Extraction Services** - All using OpenaiConfig::BaseExtractionService pattern
- **FineTune Services** - DatasetBuilder and Trainer IMPLEMENTED (Issues #26, #27 ‚úÖ)
- **Performance** - Lexicon bootstrap optimized with parallel processing

**‚ö†Ô∏è NOT READY FOR USERS** - We have a chat interface, not a Knowledge Navigator. The vision requires SHOWING data through visualizations, not just talking about it. See [STAGE_9_IN_PROGRESS.md](docs/STAGE_9_IN_PROGRESS.md)

**üìö Key Documentation:**
- `/docs/enliterator_enliterated_dataset_literate_runtime_spec_v_1.md` - Core specification
- `/docs/STAGE_9_IN_PROGRESS.md` - Knowledge Navigator TODO list (~30% done) 
- `/docs/STAGE_9_KNOWLEDGE_NAVIGATOR.md` - Stage 9 detailed specification
- `/docs/ekn-dynamic-ui-spec.md` - Dynamic UI generation from conversation
- `/docs/PROJECT_STATUS.md` - Current project status (Technical: 92%, Product: ~60%)
- GitHub Issues: https://github.com/jeremedia/enliterator/issues

### Recent Implementation Highlights

#### Stage 7: Literacy Scoring & Gaps (COMPLETE)
- **Enliteracy Score**: Composite score (0-100) with 70 minimum to proceed
- **Coverage Analysis**: Idea, temporal, spatial, and relationship coverage metrics
- **Maturity Levels**: M0-M6 progression tracking with capability assessment
- **Gap Identification**: Prioritized gaps with severity levels and recommendations
- **Comprehensive Reporting**: JSON reports with executive summaries and next steps

**Test with:**
```bash
# Calculate enliteracy score
rails enliterator:literacy:score[batch_id]

# Generate gap analysis
rails enliterator:literacy:gaps[batch_id]

# Full literacy report
rails enliterator:literacy:report[batch_id]
```

#### EKN Model Architecture - COMPLETE (2025-08-06)
- **MAJOR ACHIEVEMENT**: Refactored from IngestBatch to EKN as top-level entity
- **EKN Model**: Persistent Knowledge Navigators that own multiple IngestBatches
- **Knowledge Accumulation**: Multiple batches share same Neo4j database
- **Meta-Enliterator**: Created EKN #13 with 5 batches proving accumulation
- **GitHub Issue #53**: Architecture implementation complete

#### Stage 6: Embeddings - COMPLETE (with pgvector)
- **Implementation**: pgvector with HNSW indexing
- **OpenAI Batch API**: 50% cost savings for bulk embedding generation
- **Rights-aware filtering**: Only embeds training-eligible content
- **Performance**: Sub-second semantic search
- **Note**: Neo4j GenAI migration considered but not implemented

---

## 0) Read-first requirements

- Read `/docs/enliterator_enliterated_dataset_literate_runtime_spec_v_1.md` (the spec). Extract:
  - **Ten Pool Canon** + Optional Domain Pools.
  - **Relation Verb Glossary** (closed set; forward ‚Üî reverse).
  - **Zero-touch pipeline** stages, acceptance gates, evaluation rubric.
  - **Dialogue & Delivery** adapter contract and endnote requirements.
- Fail early if the spec is missing; do not scaffold until present.

---

## 1) System role

You are **Claude Code ‚Äî Enliterator Build Assistant**. Build a Rails 8 application that implements the **9-stage pipeline** to create Knowledge Navigators:

**Implementation Status by Stage:**

**Stages 0-8** (Technical Infrastructure - ‚úÖ COMPLETE):
0. Frame the mission through conversational onboarding ‚úÖ
1. Run intake on dropped data bundles ‚úÖ
2. Assign rights & provenance with tracking ‚úÖ
3. Bootstrap lexicon with canonical terms ‚úÖ
4. Fill pools (Ten Pool Canon) with entities and relationships ‚úÖ
5. Assemble knowledge graph (Neo4j) with path textization ‚úÖ
6. Build representations & retrieval indices (pgvector) ‚úÖ
7. Score literacy and identify gaps ‚úÖ
8. Generate deliverables (prompt packs, evaluations) ‚úÖ

**Stage 9** (The Actual Product - ‚ö†Ô∏è 30% COMPLETE):
9. **KNOWLEDGE NAVIGATOR** - Transforming infrastructure into product:
    - Conversational interface (text only) ‚ö†Ô∏è 50% (no voice)
    - Dynamic UI generation ‚ùå 0% (no visualizations)
    - Natural language wrappers ‚úÖ 70% (model understands)
    - Multimodal presentation ‚ùå 0% (text only)
    - Visual data presentation ‚ùå 0% (cannot show graphs/charts)

**CURRENT REALITY**: We have a technical pipeline and chat interface, but NOT yet a Knowledge Navigator. The vision requires SHOWING data through dynamic visualizations, not just chatting about it.

Musts: Rails 8 conventions; Postgres (ops store), Neo4j (graph), Redis, **Solid Queue/Cache**, pgvector; deterministic tests; no guessed rights.

---

## 2) Architecture

**Services**: Postgres, Redis, Neo4j, (optional) S3/MinIO for blobs, pgvector.

**Rails areas** (modules/services):

- `Ingest/` ‚Äî bundle discovery, hashing, MIME routing, OCR if needed.
- `Rights/` ‚Äî rights & provenance ledger; derives `publishability`, `training_eligibility`.
- `Lexicon/` ‚Äî canonical terms, surface/negative forms; normalization.
- `Pools/` ‚Äî Ten Pool Canon models; serializers to graph.
- `Graph/` ‚Äî Cypher writers/readers; constraints; **path textization**.
- `Embedding/` ‚Äî corpora builders (repr + canonical + path); pgvector indices.
- `Runtime/` ‚Äî Q&A orchestrators; gap/coverage ledger; persona narrative; delivery adapters.
- `MCP/` ‚Äî tool server with strict I/O validation and audits.
- `Models/` ‚Äî **Fine-tune dataset builders** and routing (see ¬ß9).

---

## 3) Zero-touch pipeline (implement exactly)

1. **Intake** ‚úÖ ‚Üí discover, hash, dedupe, partition by media.
2. **Rights & provenance** ‚úÖ ‚Üí attach license/consent; derive publishability/training eligibility; quarantine ambiguous.
3. **Lexicon bootstrap** ‚úÖ ‚Üí canonical terms, surface/negative forms, canonical descriptions.
4. **Pool filling** ‚úÖ ‚Üí extract Ten Pools + edges using the verb allow-list; assign ids, time fields; record path provenance; populate Spatial when present.
5. **Graph assembly** ‚úÖ ‚Üí load nodes/edges; enforce constraints; resolve dupes.
6. **Representations & retrieval** üöÄ ‚Üí build `repr_text` and **path sentences**; index in pgvector (exclude non-eligible text).
7. **Literacy scoring & gaps** ‚Üí coverage, flow density, temporal completeness, spatial fidelity, rights completeness, disambiguation quality; compute maturity and Enliteracy score; emit gap report.
8. **Autogenerated deliverables** ‚Üí graph ready for queries; indices; promptpacks; evaluation bundle; proposed refresh cadence.

**Acceptance gates**: as defined in the spec (id + time + rights pointer; canonical names + verbs in paths; spatial summary when used; retrieval eval passes).

---

## 4) MCP Server (contract)

**Server name**: `Enliterator MCP Server`.

### Tools

- `extract_and_link` ‚Äî Extract & link entities by pool from text (uses OpenAI **Structured Outputs**).\
  **input**: `{ text, mode?: "extract|classify|link", link_threshold?: 0.6 }`\
  **output**: `{ entities: [...], ambiguities: [...], normalized_query }`

- `search` ‚Äî Unified semantic + graph search with rights filtering.\
  **input**: `{ query, top_k?: 10..25, pools?: [...], date_from?, date_to?, require_rights?: "public|internal|any"=public, diversify_by_pool?: true, include_trace?: true }`\
  **output**: `{ items: [...], meta: { total_estimate, pool_counts } }`

- `fetch` ‚Äî Retrieve full record + relations/timeline.\
  **input**: `{ id, include_relations?: true, relation_depth?: 1..3, pools?, as_of? }`\
  **output**: `{ id, title, body, fields, pools, relations, timeline, provenance, rights, versions }`

- `bridge` ‚Äî Find items that connect concepts/pools with explicit **path**.\
  **input**: `{ a, b, top_k?: 10 }`\
  **output**: `{ bridges: [{ id, title, pools_hit, bridge_score, path }] }`

- `location_neighbors` ‚Äî Spatial neighbors, multi-year patterns, stability.\
  **input**: `{ camp_name, year?, radius: "immediate|adjacent|neighborhood" }`\
  **output**: `{ by_year: [...], stability, recurring: [...], sector_prefs: [...] }`

- `set_persona` / `clear_persona` ‚Äî Persona **Style Capsule** management with rights summary.

- **Helpers**: `explain_path(ids[])`, `rights_check(ids[], intended_use)`.

**Global rules**: include `rights` & `provenance`; return readable `trace`/`path`; treat unknown pools as no-op filters.

---

## 5) OpenAI Integration ‚Äî Production Implementation

**üìö REQUIRED READING**: See `/docs/OPENAI_CONFIGURATION.md` for current models and configuration rules.

**STATUS**: Integration complete with database-backed settings (Issue #47).

**‚ö†Ô∏è ONE RULE**: Use `OpenaiConfig::SettingsManager` for ALL model selection. Never hardcode models.

**Current Models (August 2025)**: gpt-4.1, gpt-4.1-mini, gpt-4.1-nano
**Check Configuration**: `OpenaiConfig::SettingsManager.current_configuration`

**Implementation Pattern**:

```ruby
# All services inherit from base class
class YourService < OpenaiConfig::BaseExtractionService
  def call
    super  # Model selected automatically via SettingsManager
  end
  
  protected
  
  def response_model_class
    YourResponseClass
  end
end
```

**Response Models**:

```ruby
# Response models must inherit from correct base
class YourResponseClass < OpenAI::Helpers::StructuredOutput::BaseModel
  required :field, String
  required :confidence, Float
  # Use OpenAI::ArrayOf and OpenAI::EnumOf for complex types
end

# The base service handles all OpenAI interaction
# You just define the response model and transform logic
```

**Key Requirements**:
- Read `/docs/OPENAI_CONFIGURATION.md` before ANY OpenAI work
- Use `OpenaiConfig::BaseExtractionService` for all extraction
- Check current config: `OpenaiConfig::SettingsManager.current_configuration`
- Models configured via Admin UI: https://e.dev.domt.app/admin

---

## 6) Retrieval indices (pgvector)

- **Entity index** from `repr_text` + canonical descriptions; store `pool`, `entity_id`, rights flags.
- **Path index** from textized paths; store `path_hash`, participating ids, rights flags.
- Filter at query time by `require_rights`.

---

## 7) Knowledge graph (Neo4j)

**üìç See `/docs/NEO4J.md` for complete Neo4j documentation (SINGLE SOURCE OF TRUTH)**

Quick reference:
- **URL**: `bolt://100.104.170.10:8687` (Neo4j Desktop, auth disabled)
- **Config**: `/config/initializers/neo4j.rb` (ONLY configuration that matters)
- **Multi-database**: Each EKN gets `ekn-{id}` database
- **Usage**: Always use `Graph::Connection.instance.driver`
- **Node labels**: Ten Pool Canon (Idea, Manifest, Experience, etc.)
- **Path textization**: Deterministic sentences using canonical names + verbs

---

## 8) Dialogue & Delivery

**Dialogue**: maintain session state (intent, constraints, persona, grounded entities, gaps). Show a **Path** and cite sources; spatial claims trigger a spatial endnote.

**Delivery adapters**: service objects with lifecycle: Inputs ‚Üí Preflight (rights/grounding/coverage) ‚Üí Render ‚Üí Validate ‚Üí Return. Implement: `make_webpage`, `export_markdown`, `export_pdf`, `export_table`, `make_map`, `make_timeline`, `make_outline`, `voice_script`.

Outputs must include citations, rights echo, and a concise path summary; spatial endnote when relevant.

---

## 9) Model fine-tune from the knowledge graph (base-level literate interface)

**Why**

- The base LLM understands English but not your **canon** (pools, verbs, canonical names). A small fine-tune teaches: canonical naming, verb usage, path narration, query normalization, and guardrails. This becomes the **always-on, rights-aware interface** that routes to search/fetch for facts.

**Objectives** (model should reliably):

1. Map free-form phrases to **canonical terms** and pools (Lexicon normalization).
2. Produce **path sentences** from graph snippets using the Relation Verb Glossary.
3. Suggest **next hops** (e.g., which MCP tool to call and why) given an intent.
4. Rewrite prompts into **normalized queries** that diversify by pool and respect date/space bounds.
5. Detect when the answer requires **RAG** (graph/fetch) vs. can be answered from canon.
6. Enforce **rights-first phrasing** (avoid quoting when `publishability=false`).

**Training dataset assembly** (automatic jobs):

- **Canonical term pairs**: `(user_phrase, canonical_term + pool)` from Lexicon (`surface_forms`, `negative_surface_forms`).
- **Path narrations**: random walks across 2‚Äì5 hops; input = edge list; output = path sentence.
- **Tool routing cases**: intent + constraints ‚Üí `{tool, params}` (e.g., spatial questions ‚Üí `location_neighbors`).
- **Normalization rewrites**: raw user queries ‚Üí normalized queries (time/space scoping, pool diversification).
- **Rights guardrails**: pairs showing restricted vs. public Experience phrasing.

**Data sources**

- Neo4j graph (nodes/edges), Lexicon tables, Coverage ledger, Rights ledger.
- Only include text with `training_eligibility=true`.

**Schema for fine-tune examples** (store in Postgres + emit JSONL):

```json
{ "task": "canon_map", "input": "temple of tears", "output": {"canonical": "Temple", "pool": "manifest"} }
{ "task": "path_text", "input": {"nodes": ["idea:radical_inclusion","manifest:camp_x","experience:story_1"], "edges": ["embodies","elicits"]}, "output": "Idea(Radical Inclusion) ‚Üí embodies ‚Üí Manifest(Camp X) ‚Üí elicits ‚Üí Experience(Story #1)." }
{ "task": "route", "input": {"intent": "who were our neighbors in 2019?"}, "output": {"tool": "location_neighbors", "params": {"camp_name": "...", "year": 2019, "radius": "adjacent"}} }
{ "task": "normalize", "input": "show me camps near 3:30 portal last few years", "output": "camps near 3:30 Portal, 2018‚Äì2024, diversify by pool" }
{ "task": "rights_style", "input": "quote testimonial X", "output": "paraphrase Experience; rights restricted" }
```

**Procedure**

1. Build `FineTune::DatasetBuilder` service that queries the graph and lexicon to emit stratified JSONL shards per task.
2. Split into train/val/test; keep per-task distributions.
3. Use the OpenAI Ruby gem to **create a fine-tune** on a supported lightweight model (e.g., a *mini* family) for low latency and cost. Keep base models configurable.
4. Track run ids, metrics, and the deployed model name in `runtime.models` table.
5. Add a **router**: for every user turn, first call the **fine-tuned model** to (a) normalize query, (b) decide tool plan, (c) draft a path scaffold. Then execute MCP calls and assemble the final answer.
6. Add evaluations: exact-match for `canon_map`, BLEU/ROUGE for `path_text`, tool-plan accuracy for `route`, and rights phrasing compliance.

**Ruby sketch** (non-binding):

```ruby
# app/services/fine_tune/trainer.rb
module FineTune
  class Trainer
    def self.create_job(jsonl_path)
      client = OPENAI
      client.fine_tuning.jobs.create(
        training_file: Uploads.upload(jsonl_path),
        model: ENV.fetch("OPENAI_FT_BASE", "gpt-mini"), # configurable
        suffix: "enliterator-canon-v1"
      )
    end
  end
end
```

**Routing at runtime**

- If the fine-tune returns `route: location_neighbors` ‚Üí call that tool.
- If it returns `route: search` with pool filters ‚Üí include them.
- Always pass the **normalized_query** to MCP; keep the LLM answerer separate and grounded by fetch results.

**Failure modes**

- **Drift**: re-train when graph or lexicon versions change significantly; keep version pins.
- **Overreach**: if the model starts answering from recall, clamp behavior: "Plan only; facts via MCP."
- **Latency**: cache router outputs for repeated intents; keep the base model small.

---

## 10) Persona Style Layer (optional)

Implement `set_persona/clear_persona` returning a **Style Capsule** (tone, cadence, vocabulary, devices, era, confidence, sources, rights summary). Style shapes phrasing only; facts come from fetched records. Add Solid Cache for capsules and Solid Queue jobs to build/refresh.

---

## 11) Testing & QA

- **Specs**: pipeline stages; extraction (schema conformance); graph writer; retrieval; MCP tools; adapters; persona layer; rights gating; **fine-tune dataset builder**; router accuracy.
- **Eval**: groundedness %, rights clean, coverage fit, adapter fidelity, retrieval quality; tool-plan accuracy; canon mapping accuracy; path text BLEU.
- **Red-team**: ambiguous names, missing rights, conflicting placements, sparse persona corpus, misleading routes.
- **Performance**: `search` p95 ‚â§ 800ms (`top_k ‚â§ 10`); router (fine-tuned model) p95 ‚â§ 150ms.

---

## 12) Environment & Ops

- ENV: `OPENAI_API_KEY`, `OPENAI_MODEL`, `OPENAI_MODEL_ANSWER`, `OPENAI_FT_BASE`, `OPENAI_FT_MODEL`, `DATABASE_URL`, `REDIS_URL`, `NEO4J_URL`, `VECTOR_DB_URL`, `STORAGE_BUCKET`.
- Scripts: `bin/setup`, `bin/dev` (web, worker), `bin/ci`.
- Rake: `enliterator:ingest`, `enliterator:graph:sync`, `enliterator:embed:refresh`, `enliterator:fine_tune:build`, `enliterator:evaluate`.
- Docker compose for PG/Redis/Neo4j; healthchecks; seeded demo.

---

## 13) Common Development Commands

### Initial Rails Setup
```bash
# Create new Rails 8 app
rails new enliterator --database=postgresql --skip-test --css=tailwind

# Install dependencies
bundle add openai neo4j neo4j-ruby-driver neighbor solid_queue solid_cache

# Setup databases
rails db:create
rails db:migrate
```

### Development
```bash
# Start Rails server with Solid Queue worker
bin/dev

# Run tests
bin/rails test
bin/rails test:system

# Run linters
bundle exec rubocop
bundle exec erblint --lint-all

# Run specific service tests
bin/rails test test/services/ingest/**/*_test.rb
```

### Pipeline Operations
```bash
# Ingest a data bundle
bin/rails enliterator:ingest[path/to/bundle.zip]

# Sync graph database
bin/rails enliterator:graph:sync

# Refresh embeddings
bin/rails enliterator:embed:refresh

# Build fine-tune dataset
bin/rails enliterator:fine_tune:build

# Run evaluation suite
bin/rails enliterator:evaluate
```

### Testing Completed Stages (1-5)
```bash
# Test full pipeline through Stage 5
rails runner script/test_graph_assembly.rb

# Test individual stages
rails runner script/test_lexicon_bootstrap.rb  # Stage 3

# Verify in Neo4j Browser (http://localhost:7474)
MATCH (n) RETURN labels(n)[0] as Label, count(n) as Count

# Check pipeline status
rails c
IngestBatch.pluck(:id, :name, :status)

# Run unit tests
rails test test/services/graph/
rails test test/jobs/
```

---

## 14) Coding conventions

- Normalize to **canonical names and casing**. Store synonyms/negatives in Lexicon.
- Never surface specifics (roles, placements) without a fetched source.
- Always attach rights in tool outputs; filter Experience without public consent when `require_rights=public`.
- Spatial adjacency must use `location_neighbors` (not semantic guesses).
- The **fine-tuned model routes and normalizes**, it does **not** invent facts.

---

## 15) Definition reminders (quote in code comments)

- **Literate technology**: software that converses in natural language, shows its reasoning paths and sources, adapts to user intent and constraints, and produces deliverables‚Äîtreating data as a partner in meaning rather than a passive store.
- **Enliteracy**: the process that makes a dataset literate by modeling it into pools of meaning and explicit flows between them‚Äîplus rights, provenance, and a canonical lexicon‚Äîso the system can answer *why*, *how*, and *what's next*, not only *what*.

---

## 16) System Status Checks & Server Management

### CRITICAL: Server Management Rules
- **THE ONLY WAY TO START THE SERVER**: `bin/dev`
- **NEVER** attempt to start components individually (no `rails server`, no `bundle exec rails solid_queue:start`)
- **NEVER** attempt to stop/kill server processes manually

### Checking Rails Server Status
```bash
# CORRECT way to check if Rails is running
lsof -i :3077 | grep LISTEN
```

### Checking Solid Queue Status (USE THESE EXACT QUERIES)
```bash
# Combined status check (PREFERRED)
rails runner '
  puts "=== Solid Queue Status ==="
  puts "Queues: #{SolidQueue::Job.distinct.pluck(:queue_name).join(", ")}"
  puts "Failed: #{SolidQueue::FailedExecution.count}"
  puts "In Progress: #{SolidQueue::ClaimedExecution.count}"
  puts "Finished (recent): #{SolidQueue::Job.where.not(finished_at: nil).count}"
  puts "Ready: #{SolidQueue::ReadyExecution.count}"
  puts "Scheduled: #{SolidQueue::ScheduledExecution.count}"
'

# Check failed jobs
rails runner 'failed = SolidQueue::FailedExecution.order(job_id: :asc).limit(1000); puts "Failed Jobs: #{failed.count}"'

# Check in-progress jobs
rails runner 'in_progress = SolidQueue::ClaimedExecution.order(job_id: :asc).limit(1000); puts "In Progress: #{in_progress.count}"'

# Check finished jobs
rails runner 'finished = SolidQueue::Job.where.not(finished_at: nil).order(finished_at: :desc).limit(1000); puts "Recently Finished: #{finished.count}"'
```

### Pipeline Status Checks
```bash
# Check last pipeline run
rails runner 'pr = EknPipelineRun.last; puts "Run ##{pr.id}: #{pr.status} - #{pr.current_stage}" if pr'

# Check active pipelines
rails runner 'EknPipelineRun.where(status: ["running", "paused"]).each { |pr| puts "Run ##{pr.id}: #{pr.status} at stage #{pr.current_stage}" }'
```

### Reference Documentation
- `/docs/SYSTEM_STATUS_CHECKS.md` - Comprehensive status checking procedures