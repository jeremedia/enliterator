#!/usr/bin/env ruby
# script/test_deliverables.rb
#
# Test script for Stage 8: Autogenerated Deliverables
# This script validates that all deliverables are generated correctly
# for batches with Enliteracy Score ≥70

require 'json'
require 'fileutils'

puts "=" * 80
puts "STAGE 8: AUTOGENERATED DELIVERABLES - TEST SCRIPT"
puts "=" * 80
puts

# Find a batch with literacy score ≥70
batch = IngestBatch.where('literacy_score >= ?', 70).first

unless batch
  puts "❌ No batch found with literacy score ≥70"
  puts "Creating test batch with mock score..."
  
  # Create a test batch with mock data
  batch = IngestBatch.create!(
    name: "Test Batch for Stage 8",
    status: 'literacy_scored',
    literacy_score: 75.5,
    entity_count: 100,
    relationship_count: 250,
    coverage_score: 80.0,
    maturity_level: 4
  )
  
  # Create some test entities
  5.times do |i|
    Idea.create!(
      canonical_name: "Test Idea #{i}",
      description: "Test description for idea #{i}",
      ingest_batch_id: batch.id,
      publishability: true,
      training_eligibility: true
    )
  end
  
  5.times do |i|
    Manifest.create!(
      title: "Test Manifest #{i}",
      description: "Test description for manifest #{i}",
      year: 2020 + i,
      ingest_batch_id: batch.id,
      publishability: true,
      training_eligibility: true
    )
  end
  
  5.times do |i|
    Experience.create!(
      title: "Test Experience #{i}",
      description: "Test description for experience #{i}",
      occurred_at: i.days.ago,
      ingest_batch_id: batch.id,
      publishability: i.even?,
      training_eligibility: true
    )
  end
  
  puts "✅ Test batch created with ID: #{batch.id}"
end

puts "Testing with batch: #{batch.name} (ID: #{batch.id}, Score: #{batch.literacy_score})"
puts

# Test each deliverable service individually
test_results = {
  graph_exporter: false,
  prompt_generator: false,
  evaluation_bundler: false,
  refresh_calculator: false,
  format_exporter: false,
  generation_job: false
}

# 1. Test GraphExporter
puts "1. Testing GraphExporter..."
begin
  exporter = Deliverables::GraphExporter.new(batch.id, rights_filter: 'public')
  result = exporter.call
  
  if result[:cypher_dump] && result[:query_templates] && result[:statistics]
    puts "   ✅ Graph exports generated successfully"
    puts "      - Cypher dump: #{result[:cypher_dump][:line_count]} lines"
    puts "      - Query templates: #{result[:query_templates][:template_count]} templates"
    puts "      - Statistics exported"
    test_results[:graph_exporter] = true
  else
    puts "   ❌ Graph exports incomplete"
  end
rescue => e
  puts "   ❌ GraphExporter failed: #{e.message}"
end
puts

# 2. Test PromptPackGenerator
puts "2. Testing PromptPackGenerator..."
begin
  generator = Deliverables::PromptPackGenerator.new(batch.id)
  result = generator.call
  
  total_prompts = 0
  [:discovery, :exploration, :synthesis, :temporal, :spatial].each do |type|
    if result[type] && result[type][:prompt_count]
      total_prompts += result[type][:prompt_count]
    end
  end
  
  if total_prompts > 0
    puts "   ✅ Prompt packs generated successfully"
    puts "      - Total prompts: #{total_prompts}"
    [:discovery, :exploration, :synthesis, :temporal, :spatial].each do |type|
      if result[type]
        puts "      - #{type.capitalize}: #{result[type][:prompt_count] || 0} prompts"
      end
    end
    test_results[:prompt_generator] = true
  else
    puts "   ❌ No prompts generated"
  end
rescue => e
  puts "   ❌ PromptPackGenerator failed: #{e.message}"
end
puts

# 3. Test EvaluationBundler
puts "3. Testing EvaluationBundler..."
begin
  bundler = Deliverables::EvaluationBundler.new(batch.id)
  result = bundler.call
  
  # Validate the bundle
  validation = bundler.validate
  
  if validation[:valid]
    puts "   ✅ Evaluation bundle generated and validated"
    puts "      - Test questions: #{result[:test_questions][:question_count] rescue 0}"
    puts "      - Groundedness tests: #{result[:groundedness_tests][:test_count] rescue 0}"
    puts "      - Coverage tests: #{result[:coverage_tests][:test_count] rescue 0}"
    puts "      - Validation: PASSED"
    test_results[:evaluation_bundler] = true
  else
    puts "   ❌ Evaluation bundle validation failed"
    validation[:errors].each { |err| puts "      - #{err}" }
  end
rescue => e
  puts "   ❌ EvaluationBundler failed: #{e.message}"
end
puts

# 4. Test RefreshCalculator
puts "4. Testing RefreshCalculator..."
begin
  calculator = Deliverables::RefreshCalculator.new(batch.id)
  analysis = calculator.call
  
  if analysis[:recommended_cadence] && analysis[:refresh_schedule]
    puts "   ✅ Refresh schedule calculated"
    puts "      - Recommended cadence: #{analysis[:recommended_cadence][:recommended_cadence]}"
    puts "      - Monthly cost: $#{analysis[:recommended_cadence][:monthly_cost]}"
    puts "      - Confidence: #{analysis[:recommended_cadence][:confidence_score]}%"
    test_results[:refresh_calculator] = true
  else
    puts "   ❌ Refresh calculation incomplete"
  end
rescue => e
  puts "   ❌ RefreshCalculator failed: #{e.message}"
end
puts

# 5. Test FormatExporter
puts "5. Testing FormatExporter..."
formats_tested = 0
formats_passed = 0

['json_ld', 'markdown'].each do |format|
  begin
    print "   Testing #{format} export... "
    exporter = Deliverables::FormatExporter.new(batch.id, format: format)
    result = exporter.call
    
    if result && (result[:filename] || result[:files])
      puts "✅"
      formats_passed += 1
    else
      puts "❌"
    end
    formats_tested += 1
  rescue => e
    puts "❌ (#{e.message})"
    formats_tested += 1
  end
end

if formats_passed == formats_tested
  puts "   ✅ All format exports successful (#{formats_passed}/#{formats_tested})"
  test_results[:format_exporter] = true
else
  puts "   ⚠️  Some format exports failed (#{formats_passed}/#{formats_tested} passed)"
  test_results[:format_exporter] = formats_passed > 0
end
puts

# 6. Test GenerationJob (full orchestration)
puts "6. Testing GenerationJob (full orchestration)..."
begin
  job = Deliverables::GenerationJob.new
  results = job.perform(batch.id, {
    include_graph: true,
    include_prompts: true,
    include_evaluation: true,
    include_refresh: true,
    include_formats: false,  # Skip for speed
    create_archive: false     # Skip for testing
  })
  
  if results[:success]
    puts "   ✅ GenerationJob completed successfully"
    puts "      - Output directory: #{results[:output_dir]}"
    
    # Check that files were created
    if File.directory?(results[:output_dir])
      file_count = Dir.glob(File.join(results[:output_dir], '**', '*')).select { |f| File.file?(f) }.count
      puts "      - Files generated: #{file_count}"
      
      # Check for key files
      manifest_exists = File.exist?(File.join(results[:output_dir], 'manifest.json'))
      readme_exists = File.exist?(File.join(results[:output_dir], 'README.md'))
      
      puts "      - Manifest: #{manifest_exists ? '✅' : '❌'}"
      puts "      - README: #{readme_exists ? '✅' : '❌'}"
      
      test_results[:generation_job] = manifest_exists && readme_exists
    end
  else
    puts "   ❌ GenerationJob failed: #{results[:error]}"
    if results[:errors]&.any?
      results[:errors].each { |err| puts "      - #{err}" }
    end
  end
rescue => e
  puts "   ❌ GenerationJob failed: #{e.message}"
  puts "      #{e.backtrace.first(3).join("\n      ")}"
end
puts

# Summary
puts "=" * 80
puts "TEST SUMMARY"
puts "=" * 80

total_tests = test_results.count
passed_tests = test_results.values.count(true)

test_results.each do |test, passed|
  status = passed ? "✅ PASS" : "❌ FAIL"
  puts "#{test.to_s.humanize.ljust(20)} #{status}"
end

puts
puts "Results: #{passed_tests}/#{total_tests} tests passed"

if passed_tests == total_tests
  puts
  puts "🎉 ALL TESTS PASSED! Stage 8 implementation is complete."
  puts
  puts "The Enliterator pipeline is now 100% complete!"
  puts
  puts "Next steps:"
  puts "1. Run full deliverables generation: rails enliterator:deliverables:generate[#{batch.id}]"
  puts "2. Check outputs in: tmp/deliverables/batch_#{batch.id}/"
  puts "3. Review the generated README.md for usage instructions"
  puts "4. Set up recurring generation if needed"
else
  puts
  puts "⚠️  Some tests failed. Please review the errors above."
  puts
  puts "Failed components:"
  test_results.select { |_, passed| !passed }.each do |test, _|
    puts "  - #{test.to_s.humanize}"
  end
end

# Cleanup test outputs (optional)
if ENV['CLEANUP'] == 'true'
  puts
  puts "Cleaning up test outputs..."
  FileUtils.rm_rf(Rails.root.join('tmp', 'deliverables', "batch_#{batch.id}"))
  puts "✅ Cleanup complete"
end