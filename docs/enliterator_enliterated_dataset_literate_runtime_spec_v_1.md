# Enliterator — Enliterated Dataset & Literate Runtime Spec (v1.1)

A self‑contained specification for turning a drop‑off data collection into an **enliterated dataset** that can converse, plan, and deliver multimodal outputs. It defines the pools of meaning, the flow verbs, a zero‑touch pipeline, delivery expectations, and acceptance checks so the resulting system behaves like a grounded domain expert that knows what it contains—and what it lacks.

## Definitions
- **Literate technology**: software that converses in natural language, shows its reasoning paths and sources, adapts to user intent and constraints, and produces deliverables—treating data as a partner in meaning rather than a passive store.
- **Enliteracy**: the process that makes a dataset literate by modeling it into pools of meaning and explicit flows between them—plus rights, provenance, and a canonical lexicon—so the system can answer *why*, *how*, and *what’s next*, not only *what*.

---

## 1) Zero‑touch enliteration pipeline (human drops data; system does the rest)

### 0) Frame the mission
Inputs: domain scope, key questions, risk posture, time horizon.  
Decide: target maturity tier (M0→M6), success metrics (answerability, trust, coverage, latency).  
Outputs: scope brief, evaluation goals, initial question set (e.g., “top 50”).

### 1) Intake (single drop)
Bundle (folder/ZIP/URI). System discovers files, hashes, de‑duplicates, date‑bounds, and partitions by media type. Optional micro‑manifest: `title`, `source_owner`, `intended_use` (internal/public), default rights, domain/spatial/time hints.

### 2) Rights & provenance triage
Infer source and license signals; attach **Provenance & Rights**. Derive **publishability** (for outputs) and **training_eligibility** (for representation learning). Ambiguous items quarantine; others proceed.

### 3) Lexicon & Ontology bootstrap
Induce **canonical terms**, **surface_forms** (aliases), **negative_surface_forms** (common confusions), **canonical_description** (neutral 1–2 lines). Normalize names and casing.

### 4) Pool filling
Extract candidate entities for the Ten Pool Canon and required relations. Assign **ids**, time fields, and rights pointers. Build cross‑pool edges using the **Relation Verb Glossary** (closed set). Record **path provenance**. If locations appear, populate **Spatial** and link via `located_at`; use `adjacent_to` only where explicitly supported.

### 5) Graph assembly
Load nodes/edges to the knowledge graph. Enforce unique ids, reverse edges, verb closure, cardinalities, and time constraints. Resolve duplicates; remove orphans.

### 6) Representation & retrieval indices
Derive **repr_text** for each entity (short, rights‑clean, canonical). Create retrieval indices from repr_text, canonical descriptions, and standardized **path sentences** (via the textization rule). Exclude text lacking **training_eligibility**.

### 7) Literacy scoring & gaps
Compute pool **coverage**, flow **density**, temporal **completeness**, **spatial fidelity**, **rights completeness**, **disambiguation quality**. Assign maturity (M0–M6) and a composite **Enliteracy score**. Emit a **gap report**.

### 8) Autogenerated deliverables
- Graph of meaning ready for queries.  
- Retrieval indices aligned to the Lexicon.  
- Promptpack patterns for extraction and answering (structured + persona narrative).  
- Evaluation bundle: answers with paths, citations, rights echo; spatial summaries when applicable.  
- Change log and proposed refresh cadence.

### Only‑if‑blocked interactions
Prompt a human only when: (a) rights are ambiguous, (b) spatial claims lack placement records, or (c) canonical names conflict after auto‑reconciliation. Provide defaults so the pipeline proceeds conservatively.

### Acceptance gates (automatic)
- 100% entities: **id**, a time field, and a **rights** pointer.  
- Paths use **canonical Idea names** + glossary verbs; textization round‑trips.  
- **publishability** and **training_eligibility** set for all textual artifacts.  
- If spatial claims appear, a **Spatial** summary exists (years, sector preference, stability, recurring neighbors).  
- Retrieval evaluation on the initial question set meets targets.

---

## 2) Ten Pool Canon (required for general literacy)
These ten pools form the portable contract for meaning, trust, and adaptive dialogue.

### 1) Idea
Purpose: capture the *why* (principles, theories, intents, design rationales).  
Typical: principles, doctrines, hypotheses, themes.  
Key relations: Idea→Manifest (**embodies**), Idea→Practical (**codifies**), Idea→Emanation (**influences**).  
Answers: “Which works embody Radical Inclusion?”

### 2) Manifest
Purpose: capture the *what* (concrete instances and artifacts).  
Typical: projects, items, laws, artworks, releases.  
Key relations: Manifest→Experience (**elicits**), Manifest↔Relational (**co_occurs_with**, symmetric), Manifest↔Evolutionary (**has_version** / **version_of**).  
Answers: “Show the 2023 installation and its components.”

### 3) Experience
Purpose: capture lived outcomes and perception.  
Typical: testimonials, observations, stories, reviews.  
Key relations: Experience→Emanation (**inspires**), Experience↔Practical (**validates** / **is_validated_by**).  
Answers: “What did first‑timers report feeling?”

### 4) Relational
Purpose: capture connections, lineages, and networks.  
Typical: collaborations, precedents, citations, membership edges.  
Key relations: many↔many across pools (e.g., **connects_to**, **cites**, **precedes**).  
Answers: “What cluster surrounds this work or paper?”

### 5) Evolutionary
Purpose: capture change over time.  
Typical: timelines, versions, forks, status changes.  
Key relations: Evolutionary→Manifest (**version_of** / reverse **has_version**), Evolutionary→Idea (**refines** / reverse **is_refined_by**).  
Answers: “How did this practice change from 2015 to 2025?”

### 6) Practical
Purpose: capture how‑to and tacit knowledge.  
Typical: guides, SOPs, checklists, recipes, playbooks.  
Key relations: Practical↔Experience (**validated_by** / **validates**), Practical↔Idea (**derived_from** / **informs**).  
Answers: “What steps make this safe and repeatable?”

### 7) Emanation
Purpose: capture ripple effects and downstream influence.  
Typical: adoptions, remixes, movements, policies.  
Key relations: Emanation↔Idea (**feeds_back** / **is_fed_by**), Emanation↔Relational (**diffuses_through**).  
Answers: “Where did this approach spread next?”

### 8) Provenance and Rights
Purpose: capture source, attribution, consent, license, lineage.  
Typical: citations, collection methods, rights statements, data‑use agreements.  
Key relations: annotates every node and edge.  
Derived fields: **publishability** (for outputs), **training_eligibility** (for representation).  
Answers: “Can this be published, and under what terms?”

### 9) Lexicon and Ontology
Purpose: capture definitions, synonyms, types, and schema versions.  
Typical: term entries, controlled vocabularies, unit systems, type hierarchies.  
Key relations: Lexicon→all pools (**normalizes**, **disambiguates**).  
Key retrieval fields: **canonical_description**, **surface_forms**, **negative_surface_forms**.  
Answers: “Map ‘camp’ to the canonical type and find equivalents.”

### 10) Intent and Task
Purpose: capture what users ask and how tasks are fulfilled (now including artifacts).  
Typical: questions, prompts, goals, preferred presentations, success signals.  
Key relations: Intent→Relational (**requests**), Intent→Practical (**selects_template**), Intent→(Flows) (**traverses_pattern**), Intent→Manifest (**targets**, optional).  
Extended fields (see §5): `deliverable_type`, `modality`, `constraints`, `adapter_name`, `adapter_params`, `evaluation`.

---

## 3) Optional Domain Pools (add when the domain demands it)
Promote only when a concept has an independent lifecycle and many‑to‑many relations.

### 11) Actor and Role
Purpose: people and organizations with roles and permissions.  
When to add: authorship, governance, or access rules are central.  
Key relations: Actor→Manifest (**authors** / **owns**), Actor→Relational (**member_of**), Actor→Experience (**reports**).

### 12) Spatial
Purpose: places, regions, geometries, spatial hierarchies.  
When to add: location logic or geo queries are first‑class.  
Key relations: Manifest→Spatial (**located_at** / reverse **hosts**), Spatial↔Spatial (**adjacent_to**, symmetric), Spatial→Relational (**in_sector_with**).

### 13) Evidence and Observation
Purpose: primary data such as measurements, logs, transcripts (distinct from **Experience**, which is subjective/lived).  
When to add: claims must trace to raw observations.  
Key relations: Evidence→Idea (**supports** / **refutes**), Evidence→Practical (**validates**), Evidence→Manifest (**measures**).

### 14) Risk and Governance
Purpose: hazards, mitigations, approvals, compliance states.  
When to add: safety and policy gates shape what can be shown.  
Key relations: Risk→Practical (**requires_mitigation**), Governance→Provenance (**constrains**).

### 15) Method and Model
Purpose: methods, methodologies, evaluation patterns.  
When to add: reproducibility and method drift matter.  
Key relations: Method→Evidence (**produces**), Method→Practical (**standardizes**).

---

## 4) Cross‑cutting aspects (annotate, don’t promote)
Attach across pools:
- **Sensitivity class** (public / internal / restricted).  
- **Confidence / evidence_strength**.  
- **Language / locale**.  
- Value metrics and quality scores.  
- Presentation choices and rendering preferences.  
- Lightweight tags without their own lifecycle.

---

## 5) Dialogue & Delivery layers (make it usable)

### Dialogue layer
- **Session state**: intent, constraints, time/space bounds, chosen persona (optional), accepted assumptions, grounded entities, pending deliverables.  
- **Gap‑aware**: can state what is missing and propose minimal next intake.  
- **Explanation**: every substantive answer can show a cross‑pool **Path** and cite sources; spatial claims trigger **Spatial** context.

### Delivery layer
- **Delivery adapters** (contract): turn grounded answers into artifacts—webpage, markdown, PDF, table/CSV, map, timeline, storyboard, outline, voice script.  
- **Preflight**: rights check for intended use; every concrete claim mapped to fetched sources; spatial endnote if spatial claims appear; coverage check.  
- **Postflight**: include citations, rights echo, and a concise path summary; record what was rendered and why.

### Intent & Task (extended minimal fields)
`id`, `user_goal`, `query_text`, `observed_at`, `presentation_preference`, `outcome_signal`, `success_criteria`, `repr_text`,  
**`deliverable_type`** (webpage | markdown | pdf | table | map | timeline | outline | storyboard | voice_script),  
**`modality`** (text | voice | mixed), **`constraints`**, **`adapter_name`**, **`adapter_params`**, **`evaluation`** (groundedness, coverage, readability goals).

### Coverage ledger & negative knowledge
- **Coverage ledger**: per pool, density by time/topic/space.  
- **Negative knowledge**: canonical “not present” entries (e.g., *no verified placement records for 2019*).  
- **Answer behavior**: when gaps intersect a request, state what’s known, what’s missing, and the minimal intake to close it.

### Evaluation rubric (for deliverables)
1) **Groundedness**: % of sentences backed by fetched items or clearly marked as inference.  
2) **Rights**: no violations; correct attribution; Experience consent respected.  
3) **Coverage fit**: spans the pools/scope implied by the request.  
4) **Adapter fidelity**: artifact matches schema (citations, rights note, spatial line when needed).  
5) **User utility**: satisfies constraints (audience, length, clarity); latency budget respected.

---

## 6) Relation Verb Glossary (forward ↔ reverse; closed set)
Use these verbs for clarity and comparability; include reverse names where applicable.
- **embodies** (Idea→Manifest) ↔ **is_embodiment_of**  
- **elicits** (Manifest→Experience) ↔ **is_elicited_by**  
- **influences** (Idea/Emanation→*) ↔ **is_influenced_by**  
- **refines** (Evolutionary→Idea) ↔ **is_refined_by**  
- **version_of** (Evolutionary→Manifest) ↔ **has_version**  
- **co_occurs_with** (Relational↔Relational) (symmetric)  
- **located_at** (Manifest→Spatial) ↔ **hosts**  
- **adjacent_to** (Spatial↔Spatial) (symmetric)  
- **validated_by** (Practical→Experience) ↔ **validates**  
- **supports** / **refutes** (Evidence→Idea)  
- **diffuses_through** (Emanation↔Relational)

**Canonical Idea names**: paths should use Lexicon/Ten Principles canonical Idea labels. Store synonyms as Lexicon entries; normalize in answers and citations.

---

## 7) Flow semantics, path textization, and cardinality
- Declare direction and cardinality for each flow (one→many, many→one, many↔many).  
- Support reverse traversals with possibly different semantics.  
- Track path provenance so answers can cite how they were assembled.  
- Provide a **path textization rule** that renders any path as one sentence using canonical Idea names and glossary verbs (e.g., *Idea → embodies → Manifest → elicits → Experience*).

---

## 8) Minimal ontology fields per pool (starter set)
Add **id** and a time field to enable merging and time‑travel reads. Use **valid_time** (start/end) when entities persist; **observed_at** for instants. Include **repr_text** (short, rights‑clean, canonical) where noted.

- **Idea**: id; label; abstract; principle tags; authorship; inception date; **valid_time**; **repr_text**.  
- **Manifest**: id; label; type; components; time bounds; **spatial_ref** (when Spatial present); **valid_time**; **repr_text**.  
- **Experience**: id; **agent_label** (link to Actor when available); context; narrative text; sentiment; date; **observed_at**; **repr_text**.  
- **Relational**: id; relation type; source; target; strength; period; **valid_time**.  
- **Evolutionary**: id; change note; prior ref; timestamp; **version_id**; **valid_time**.  
- **Practical**: id; goal; steps; prerequisites; hazards; validation refs; **valid_time**; **repr_text**.  
- **Emanation**: id; influence type; target context; pathway; evidence; **valid_time**; **repr_text**.  
- **Provenance and Rights**: id; source ids; collectors; method; license; consent; embargo; **publishability** (derived); **training_eligibility** (derived); **valid_time**.  
- **Lexicon and Ontology**: id; term; definition; **canonical_description**; **surface_forms**; **negative_surface_forms**; type mapping; unit system; schema version; **valid_time**.  
- **Intent and Task**: id; user goal; query text; presentation preference; outcome signal; success criteria; **observed_at**; **repr_text**; see §5 for delivery extensions.

**Note (Experience ↔ Actor)**: *Experience* uses **agent_label** and links to **Actor and Role** when that pool is present to avoid required→optional coupling.

---

## 9) Promotion and de‑promotion tests
Create a new pool only if **all** are true:
1) The concept introduces entities with their own lifecycle.  
2) It connects to several pools via distinct relation types.  
3) Queries become simpler and clearer when it is first‑class.  
4) Governance or reuse improves when separated from existing pools.

Fold a pool back into an aspect if **all** are true:
1) Its lifecycle is bound to another pool.  
2) Edges are sparse or redundant.  
3) Queries do not simplify with it as first‑class.

---

## 10) Maturity alignment
A practical ladder for adopting pools, flows, and delivery.
- **M0 Catalog**: Manifest only; minimal metadata; no flows.  
- **M1 Narrative**: seven core pools present with basic flows.  
- **M2 Literate**: dense cross‑pool flows plus Lexicon and Ontology.  
- **M3 Trusted**: Provenance and Rights enforced on outputs.  
- **M4 Adaptive**: Intent and Task steer continuous learning and presentation.  
- **M5 Orchestrated Delivery**: delivery adapters, plan→critique→render loop, file outputs with citations & rights echo.  
- **M6 Autopilot (opt‑in)**: multi‑step tasks, scheduled refreshes, proactive gap‑closure proposals—always rights‑gated and reversible.

---

## 11) Acceptance checks (for curators and reviewers)
- Every entity has **id**, a time field (**valid_time** or **observed_at**), and a **rights** pointer.  
- Paths use **canonical Idea names** and verbs from the **Relation Verb Glossary**; path textization round‑trips.  
- **publishability** and **training_eligibility** are set for all textual artifacts intended for external use or internal representation.  
- If *Spatial* claims appear, a **Spatial** summary is present (years analyzed; sector preference; stability; recurring neighbors).  
- Disambiguation quality: key entities include **surface_forms** (≥3) and at least one **negative_surface_form**.  
- **Experience** items never surface restricted content when publishability is required.  
- New pool proposals pass the **Promotion test** (and fail the **De‑promotion** test).  
- Deliverables meet the **Evaluation rubric** and include citations and rights echo.

---

## 12) Curation guidance (keep it portable)
- Prefer a small set of verbs and re‑use them across domains.  
- Normalize names and casing through the Lexicon; keep synonyms and negative forms as entries.  
- Record minimal but sufficient time bounds to support “as‑of” reasoning.  
- Keep Spatial optional, but when present, use **located_at**, **adjacent_to**, and sector/portal conventions consistently.  
- Distinguish **Evidence** (primary data) from **Experience** (subjective narrative) and bind each to **Provenance and Rights**.  
- Derive **repr_text** from canonical labels + one disambiguating cue; keep it short and rights‑clean.

