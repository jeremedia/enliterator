# Enliterator Project Status

**Last Updated**: 2025-08-05

## Overview
Enliterator is a Rails 8 application that transforms dropped data collections into **enliterated datasets** - knowledge graphs that can converse, cite sources, and produce deliverables.

## Pipeline Implementation Progress

### âœ… Completed (Stages 1-5)

#### Stage 1: Intake
- IngestBatch and IngestItem models
- File discovery, hashing, deduplication
- MIME type detection and partitioning

#### Stage 2: Rights & Provenance  
- ProvenanceAndRights model with publishability/training_eligibility
- Rights::AssignmentJob for automatic assignment
- Rights quarantine for ambiguous items

#### Stage 3: Lexicon Bootstrap
- Lexicon::BootstrapJob orchestrator
- Term extraction with OpenAI Structured Outputs
- Surface forms and negative forms generation
- Graph::LexiconWriter for Neo4j sync

#### Stage 4: Pool Filling
- All Ten Pool Canon models implemented
- Pools::ExtractionJob with entity/relation extraction
- Verb glossary enforcement
- Path provenance tracking

#### Stage 5: Graph Assembly
- Neo4j knowledge graph construction
- Schema constraints and indexes
- Duplicate resolution and orphan removal  
- Path textization for readable paths
- Comprehensive integrity verification

### ğŸš€ Next Priority

#### Stage 6: Representations & Retrieval
- **Status**: Ready to start
- **GitHub Issue**: #17
- **Key Tasks**:
  - pgvector embedding generation
  - Entity and path indices
  - Rights-aware filtering
  - Retrieval optimization

### â³ Upcoming (Stages 7-8 + Beyond)

#### Stage 7: Literacy Scoring & Gaps
- Coverage metrics
- Maturity assessment (M0-M6)
- Gap identification

#### Stage 8: Autogenerated Deliverables
- Query-ready graph
- Prompt packs
- Evaluation bundles

#### MCP Server Implementation
- Core tools (extract_and_link, search, fetch, bridge)
- Spatial tools (location_neighbors)
- Persona management

#### Fine-tuning & Runtime
- Dataset generation from graph
- Model training with OpenAI
- Dialogue system
- Delivery adapters (webpage, PDF, etc.)

## Key Technical Components

### Infrastructure
- **Database**: PostgreSQL with pgvector
- **Graph DB**: Neo4j 
- **Queue**: Solid Queue
- **Cache**: Solid Cache
- **AI**: OpenAI Responses API with Structured Outputs

### Testing
- Unit tests for all services
- Integration test scripts in `/script`
- Neo4j verification queries

### Documentation
- `/docs/enliterator_enliterated_dataset_literate_runtime_spec_v_1.md` - Core specification
- `/docs/STAGE_5_GRAPH_ASSEMBLY_COMPLETE.md` - Latest implementation
- `/CLAUDE.md` - AI assistant guidance

## How to Test Current Implementation

```bash
# Test full pipeline through Stage 5
rails runner script/test_graph_assembly.rb

# Check Neo4j graph (http://localhost:7474)
MATCH (n) RETURN labels(n)[0] as Label, count(n) as Count

# View pipeline status
rails c
IngestBatch.pluck(:id, :name, :status)
```

## GitHub Issues

### Open High-Priority
- #17 - Stage 6: Representations & Retrieval (NEXT)
- #23 - Core MCP Tools
- #26 - Fine-tune Dataset Generation
- #30 - Dialogue System
- #36 - Performance Optimization
- #38 - Security Hardening

### Recently Closed
- #15 - Stage 5: Graph Assembly âœ…
- #14 - Stage 4: Pool Filling âœ…
- #13 - Stage 3: Lexicon Bootstrap âœ…

## Repository Structure

```
enliterator/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ models/          # Ten Pool Canon + core models
â”‚   â”œâ”€â”€ jobs/
â”‚   â”‚   â”œâ”€â”€ graph/       # Graph assembly jobs
â”‚   â”‚   â”œâ”€â”€ lexicon/     # Lexicon extraction
â”‚   â”‚   â”œâ”€â”€ pools/       # Entity extraction
â”‚   â”‚   â””â”€â”€ rights/      # Rights assignment
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ graph/       # Neo4j operations
â”‚       â”œâ”€â”€ lexicon/     # Term processing
â”‚       â”œâ”€â”€ pools/       # Entity extraction
â”‚       â””â”€â”€ rights/      # Rights derivation
â”œâ”€â”€ docs/                # Specifications and documentation
â”œâ”€â”€ script/              # Test and utility scripts
â””â”€â”€ test/                # Unit and integration tests
```

## Next Actions

1. **Start Stage 6**: Implement pgvector embeddings and retrieval indices
2. **Performance**: Optimize Neo4j queries and add caching
3. **Testing**: Expand test coverage for graph operations
4. **Documentation**: Update API documentation for completed services

## Contact & Resources

- GitHub: https://github.com/jeremedia/enliterator
- Issues: https://github.com/jeremedia/enliterator/issues
- Spec: `/docs/enliterator_enliterated_dataset_literate_runtime_spec_v_1.md`